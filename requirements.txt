torch==2.4.0
transformers==4.36.2 # may update to transformers==4.43.4
scipy # use 1.10.1 for pyserini bm25 retrieval
packaging
sentencepiece
datasets
deepspeed==0.15.4
accelerate==0.31.0
peft>=0.4.0
bitsandbytes>=0.41.1
evaluate>=0.4.0
tokenizers>=0.13.3
protobuf
openai>=1.0.0
tiktoken
sentence_transformers==2.7.0
rouge_score
wandb
termcolor
jsonlines
unidic-lite
einops
# directly install flash-attn will be interupted, need to install pytorch first
# flash-attn==2.5.8
auto-gptq
fire
# for ifeval
nltk
langdetect
immutabledict
# sparse and dense retrieval
pyserini==0.36.0
